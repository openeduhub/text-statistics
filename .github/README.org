#+title: GitHub Specific README

The ~Python~ script [[file:../src/readingtime/readingtime.py]] estimates the reading time of a given text, using the following model:
- It assumes a base-line reading speed of 200 WPM.
- This reading speed is adjusted w.r.t. the Flesch-Reading-Ease of the given text.

In particular, we set that the "real" reading speed of the text is equal to $200 \cdot (\frac{1}{2} \exp^{\ln 4 / 121.5 \cdot s})$, where $s$ is the Flesch-Reading-Ease.
Thus, the reading-speed is halved at a reading ease of $0$ (very difficult) and double at a reading ease of $121.5$ (the highest possible value).
We chose an exponential function for this purpose because of its monotonicity and the fact that it is always above 0.
Other, possibly more sophisticated models, are also possible and could be studied and implemented in the future.

[[file:../src/readingtime/main.py]] provides a microservice, see [[Usage]].

* Installation
** As Python Package
This package can be installed as a Python package by cloning this repository and running
#+begin_src sh
pip install .
#+end_src

** As Nix Flake
Alternatively, with [[https://nixos.org/][nix]] installed (and the [[https://nixos.wiki/wiki/Flakes#Enable_flakes][flakes]] feature enabled), one can run the microservice through
#+begin_src sh
nix run github:openeduhub/text-statistics
#+end_src

** As Docker Image
A docker image can be built through
#+begin_src sh
nix build github:openeduhub/text-statistics#docker
#+end_src
The resulting image has to be loaded and executed via
#+begin_src sh
docker load < /path/to/result
docker run -p 8080:8080 readingtime:1.0.2
#+end_src

* Usage
Once the microservice is running, text can be supplied through ~json~ queries on the =analyze-text= subdomain.
For example:
#+begin_src sh
curl -d '{"text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. This is another sentence."}' -H "Content-Type: application/json" -X POST localhost:8080/analyze-text
#+end_src

The result contains the Flesch-ease, the corresponding classification, and the predicted reading time (in seconds):
#+begin_src json
{"flesh-ease": 43.39452054794519, "classification": "Schwer", "reading-time": 29.987166756508653}
#+end_src
